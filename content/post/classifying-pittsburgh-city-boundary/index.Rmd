---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Modeling the Pittsburgh City Boundary"
subtitle: ""
summary: ""
authors: [Conor Tompkins]
tags: [R, Pittsburgh, Allegheny County]
categories: [R, Pittsburgh, Allegheny County]
date: 2020-08-14T15:07:55-04:00
lastmod: 2020-08-14T15:07:55-04:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

## Intro

My goal is to create a classification model that can distinguish between tracts that are inside the city or outside the city.

History of Pitt border


This code loads the packages I need, configures some options, and sets the seed.
```{r}
#set up environment
library(tidyverse)
library(tidymodels)
library(janitor)
library(tidycensus)
library(sf)
library(hrbrthemes)
library(GGally)

theme_set(theme_ipsum(base_size = 20))

options(scipen = 999, digits = 4, tigris_use_cache = TRUE)

set.seed(1234)
```
I created a small Shiny app that let me select which tracts are inside the city borders. I will go over that in a future post. This loads the tracts from the Census API and pulls the data from the Shiny app.
```{r}
#load data about census tracts
tracts <- get_decennial(year = 2010, state = "PA", county = "Allegheny County", 
                        variables = "P001001",
                        geography = "tract", geometry = TRUE)

city_tracts <- read_csv("data/selected_tracts.csv", col_types = cols("c", "l")) %>% 
  filter(selected == TRUE)

glimpse(city_tracts)
```

This reads in the boundary shapefile and plots it against the tracts.
```{r}
pgh_official_boundary <- st_read("data/Pittsburgh_City_Boundary-shp") %>% 
  mutate(geography = "City boundary") %>% 
  st_transform(crs = "NAD83") %>% 
  st_cast("POLYGON") %>% 
  filter(FID != 7)

tracts %>% 
  left_join(city_tracts) %>% 
  mutate(type = case_when(selected == TRUE ~ "city",
                          is.na(selected) ~ "non_city")) %>% 
  ggplot() +
  geom_sf(aes(fill = type), size = .1) +
  geom_sf(data = pgh_official_boundary, color = "white", linetype = 2, alpha = 0) +
  theme_void()
```

This reads in all the data from the Census that I will consider for the model. Generally I use the following types of data:

* Housing
  ** Percent of housing units owned outright
  ** Percent of housing units owned with a mortgage
  ** Percent of housing units rented
* Demographics
  ** Percent of people in the tract that are
    *** White
    *** Black
* Population density
* Economic data
  ** Number of workers that live in the tract
  ** Number of jobs in the tract

```{r}
all_data <- read_csv("data/combined_census_data_tract.csv", col_types = cols(.default = "c")) %>%
  left_join(city_tracts) %>% 
  mutate(type = case_when(selected == TRUE ~ "city",
                          is.na(selected) ~ "non_city")) %>% 
  mutate(across(pct_units_owned_loan:housed_population_density_pop_per_square_km, as.numeric)) %>% 
  select(GEOID, type, everything()) %>%
  mutate(flag_void = (total_population == 0 &
                        housed_population_density_pop_per_square_km == 0 &
                        jobs == 0 &
                        workers == 0) %>% as.factor) %>% 
  select(-c(flag_void, selected, total_population_housed))

glimpse(all_data)
```

This plot compares all of the variables against each other. I used this to identify covariance and determine which variables should be excluded.
```{r eval=FALSE}
#eda
pairwise_plot <- all_data %>% 
  select(-c(GEOID)) %>% 
  ggpairs(aes(color = type)) +
  theme(axis.text = element_text(size = 8))
```

insert pairwise plot here

This finalizes the data I will model.
```{r}
census_combined <- all_data %>% 
  select(GEOID, type, 
         pct_units_owned_loan, pct_units_owned_entire, pct_units_rented,
         housed_population_density_pop_per_square_km,
         pct_white, pct_black,
         workers, jobs)

glimpse(census_combined)
```


```{r}
#split
split <- initial_split(census_combined, prop = 3/4, strata = type)
training <- training(split)
testing <- testing(split)
```

```{r}
#recipe
model_recipe <- recipe(type ~ ., data = training) %>% 
  update_role(GEOID, new_role = "id") %>% 
  step_normalize(all_predictors())# %>% 
  #step_mutate(type = as.factor(type))

model_recipe_prep <- model_recipe %>% 
  prep(strings_as_factors = FALSE)

model_recipe_prep %>% 
  summary()
```

```{r}
#create model specifications
lm_model <- logistic_reg(mode = "classification") %>% 
  set_engine("glm")

ranger_model <- rand_forest(trees = 1000, mode = "classification") %>%
  set_engine("ranger", importance = "impurity")
```


```{r}
#workflow
#lm
lm_workflow <- workflow() %>% 
  add_recipe(model_recipe_prep) %>% 
  add_model(lm_model)

lm_workflow %>% 
  fit(juice(model_recipe_prep)) %>% 
  predict(juice(model_recipe_prep)) %>% 
  bind_cols(juice(model_recipe_prep)) %>% 
  mutate(type = as.factor(type)) %>% 
  metrics(truth = type, estimate = .pred_class)
```

The logistic regression model does a pretty good job on the training set, but I wanted to know if that was just a one-off performance. The next code chunk creates cross-validation folds with Monte Carlo. Validating the model against these folds should tell me if the model is stable.
```{r}
validation <- mc_cv(training, prop = 3/4, times = 100, strata = type)

lm_res <- lm_workflow %>% 
  fit_resamples(resamples = validation) %>% 
  mutate(model = "lm")

lm_res %>% 
  collect_metrics()
```

```{r}
#rf
rf_workflow <- workflow() %>% 
  add_recipe(model_recipe_prep) %>% 
  add_model(ranger_model)

rf_res <- rf_workflow %>% 
  fit_resamples(resamples = validation) %>% 
  mutate(model = "rf")

rf_res
```

```{r}
rf_res %>% 
  collect_metrics()
```

```{r}
combined_res <- bind_rows(rf_res, lm_res)

combined_res %>% 
  unnest(.metrics) %>% 
  ggplot(aes(.estimate, color = model, fill = model)) +
  geom_density(alpha = .5) +
  facet_wrap(~.metric)

#rf does much better in general. i will choose that one
```


```{r}
### predict on training
predictions_training <- fit(rf_workflow, juice(model_recipe_prep)) %>% 
  predict(juice(model_recipe_prep)) %>% 
  bind_cols(juice(model_recipe_prep)) %>% 
  mutate(type = as.factor(type))

#rf does much better on full training set
predictions_training %>% 
  metrics(truth = type, estimate = .pred_class)

#failures are false negatives
predictions_training %>% 
  conf_mat(truth = type, estimate = .pred_class)
```


```{r}
#roc
df_roc_curve <- fit(rf_workflow, juice(model_recipe_prep)) %>% 
  predict(juice(model_recipe_prep), type = "prob") %>% 
  bind_cols(juice(model_recipe_prep)) %>% 
  mutate(type = as.factor(type)) %>% 
  roc_curve(truth = type, .pred_city)

df_roc_curve %>% 
  autoplot()
```


```{r}
#variable importance
var_imp <- rf_workflow %>% 
  fit(juice(model_recipe_prep)) %>% 
  pull_workflow_fit() %>% 
  vip::vi()

var_imp %>%
  mutate(Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(Importance, Variable)) +
  geom_point()
```


```{r}
### predict on testing
predictions_testing <- fit(rf_workflow, bake(model_recipe_prep, testing)) %>% 
  predict(bake(model_recipe_prep, testing)) %>% 
  bind_cols(bake(model_recipe_prep, testing)) %>% 
  mutate(type = as.factor(type))

#rf only does very slightly worse on test set
predictions_testing %>% 
  metrics(truth = type, estimate = .pred_class)
```

```{r}
#failures are false positives this time
predictions_testing %>% 
  conf_mat(truth = type, estimate = .pred_class)
```


```{r}
#map results

#predict on full dataset
#probabilities
full_predictions <- fit(rf_workflow, bake(model_recipe_prep, census_combined)) %>% 
  predict(bake(model_recipe_prep, census_combined), type = "prob") %>% 
  bind_cols(bake(model_recipe_prep, census_combined)) %>% 
  mutate(type = as.factor(type))


full_predictions_small <- full_predictions %>% 
  select(GEOID, type, contains(".pred")) %>% 
  pivot_longer(cols = contains(".pred"))
```


```{r}
tracts %>% 
  select(GEOID) %>% 
  left_join(full_predictions_small, by = "GEOID") %>% 
  mutate(name = case_when(name == ".pred_city" ~ "predicted_city",
                          name == ".pred_non_city" ~ "predicted_non_city")) %>% 
  filter(name == "predicted_city") %>% 
  ggplot() +
  geom_sf(aes(fill = value), color = NA) +
  geom_sf(data = pgh_official_boundary, alpha = 0, color = "black") +
  geom_sf(data = pgh_official_boundary, alpha = 0, color = "yellow", linetype = 2) +
  labs(title = 'Probability of "city"',
       fill = "Probability") +
  scale_fill_viridis_c(labels = scales::percent) +
  theme_void()
```


```{r}
tracts %>% 
  select(GEOID) %>% 
  left_join(full_predictions_small, by = "GEOID") %>% 
  mutate(name = case_when(name == ".pred_city" ~ "predicted_city",
                          name == ".pred_non_city" ~ "predicted_non_city")) %>% 
  filter(name == "predicted_non_city") %>% 
  ggplot() +
  geom_sf(aes(fill = value), color = NA) +
  geom_sf(data = pgh_official_boundary, alpha = 0, color = "black") +
  geom_sf(data = pgh_official_boundary, alpha = 0, color = "yellow", linetype = 2) +
  labs(title = 'Probability of "non-city"',
       fill = "Probability") +
  scale_fill_viridis_c(labels = scales::percent) +
  theme_void()
```


```{r}
#binary predictions
full_predictions_binary <- fit(rf_workflow, bake(model_recipe_prep, census_combined)) %>% 
  predict(bake(model_recipe_prep, census_combined)) %>% 
  bind_cols(bake(model_recipe_prep, census_combined)) %>% 
  mutate(type = as.factor(type),
         correct = type == .pred_class)


full_predictions_binary_small <- full_predictions_binary %>% 
  select(GEOID, type, .pred_class, correct)
```


```{r}
tracts %>% 
  select(GEOID) %>% 
  left_join(full_predictions_binary_small, by = "GEOID") %>% 
  ggplot() +
  geom_sf(aes(fill = correct), color = NA, alpha = .7) +
  geom_sf(data = pgh_official_boundary, alpha = 0, color = "black") +
  geom_sf(data = pgh_official_boundary, alpha = 0, color = "yellow", linetype = 2) +
  scale_fill_viridis_d() +
  labs(title = "Prediction outcome",
       fill = NULL) +
  theme_void()
```




## References

http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/#split-into-traintest
https://www.brodrigues.co/blog/2018-11-25-tidy_cv/
https://agailloty.rbind.io/en/post/tidymodels/
https://alison.rbind.io/post/2020-02-27-better-tidymodels/
https://hansjoerg.me/2020/02/09/tidymodels-for-machine-learning/
https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c
https://www.benjaminsorensen.me/post/modeling-with-parsnip-and-tidymodels/
https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/

